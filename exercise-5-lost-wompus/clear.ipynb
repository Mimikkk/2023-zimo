{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zaawansowane Metody Inteligencji Obliczeniowej\n",
    "# Zadanie domowe 5 (10 pkt.)\n",
    "### Prowadzący: Michał Kempka, Marek Wydmuch\n",
    "### Autor: twoje imię i nazwisko + numer indeksu, grupa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Zadanie 5\n",
    "\n",
    "Świat jest prostokątem, o wymiarach **N** wierszy na **M** kolumn. Każde pole może być jamą (1), wyjście (2) lub puste (0). Celem Wumpusa jest najszybsze dotarcie do wyjścia.\n",
    "Wumpus porusza się w świecie wykonując ruchy **UP**, **DOWN**, **RIGHT**, **LEFT**.\n",
    "Świat nie ma ścian i jest cykliczny, to znaczy, że wykonując ruch **UP** z pola w pierwszym (górnym) wierszu,\n",
    "Wumpus (zwykle) dorze do pola w ostatnim (dolnym) wierszu; analogicznie w przypadku ruchw poziomych.\n",
    "Wumpus jest otumaniony, dlatego jest niepewny swoich akcji.\n",
    "Wykonując ruch z prawdopodobieńśtwem **p** (np. 0.8) dotrze do docelowego pola, ale z prawd. (1-**p**)/4 (np. 0.05) znajdzie się na jednym z czterech pól sąsiadujących z polem docelowym.\n",
    "\n",
    "W świecie Wumpusa występują jamy.\n",
    "Dla otumanionego Wumpusa nie są one jednak groźne, a stanowią dla niego ważne punkty orientacyjne.\n",
    "Jeśli Wumpus stanie na polu, na którym jest jama, Wumpus odnotowuje ten fakt z prawdopodobieństwem **pj** (np. 0.7).\n",
    "Niestety, ze względu na otumanienie, czasem (z prawd. **pn** (np. 0.1)) wydaje mu się, że wpadł do jamy, gdy tymczasem nic takiego nie miało miejsca.\n",
    "\n",
    "Wumpus posiada mapę świata, ale nie ma pojęcia, gdzie się znajduje. Pomóż mu w jak najmniejszej liczbie ruchów dotrzeć do pola oznaczonego jako Wyjście.\n",
    "Celem minimalizacji jest dojść Wumpusem w **średnio** jak najmniejszej liczbie kroków przy niedoskonałej wiedzy i niedoskonałej motoryce.\n",
    "#### Uwaga: Możesz dowolnie modyfikować elementy tego notebooka (wstawiać komórki i zmieniać kod) o ile nie napisano gdzieś inaczej."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repozytorium\n",
    "Do wykonania zadania potrzebny jest pakiet **misio**, który zainstaluje środowisko i wszystkie dependencje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip3 install git+https://github.com/mihahauke/misio_labs\n",
    "\n",
    "# lub:\n",
    "# !git clone https://github.com/mihahauke/misio_labs\n",
    "# !cd misio\n",
    "# !sudo pip3 install .\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przykładowy świat\n",
    "Do oceny rozwiązań zostaną użyte dwa pliki 2015.in i 2016.in, dostarczone razem z tym notebookiem. Pliki te zawierają wiele map. By wczytać dowolny świat z plików wejściowych możemy użyć poniższego kodu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from misio.lost_wumpus.util import load_input_file\n",
    "\n",
    "worlds = load_input_file(\"2015.in\")\n",
    "# każdy świat opisany jest przez mapę i odpowiednie prawdopodobieńśtwa\n",
    "m, p, pj, pn = worlds[0]\n",
    "print(m, p, pj, pn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losowy agent\n",
    "Poniżej znajduje się implementacja prostego, losowego agenta ( dziedziczącego po misio.lost_wumpus.agents.AgentStub) implementującego następujące funkcje:\n",
    "**move** zwracającą losowy ruch, który ma wykonać agent.\n",
    "* **sense**(bool) - aktualizacja wiedzy na podstawie wykrycia (lub nie) jamy - w przypadku losowego agenta nic się nie dzieje\n",
    "* **move**() - metoda zwracająca jeden (losowy) z ruchów z klasy misio.lost_wumpus._wumpus.Action\n",
    "* **reset**() - zresetowanie wiedzy agenta na potrzeby wielu testów na tej samej mapie - znowu, w przypadku agenta losowego nie jest to potrzebne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from misio.lost_wumpus.agents import AgentStub\n",
    "from misio.lost_wumpus._wumpus import Action\n",
    "\n",
    "class RandomAgent(AgentStub):\n",
    "    def __init__(self, m, p, pj, pn):\n",
    "        super(RandomAgent, self).__init__(m, p, pj, pn)\n",
    "\n",
    "    def move(self):\n",
    "        # zrób losowy ruch\n",
    "        return np.random.choice(Action)\n",
    "\n",
    "    def sense(self, sensory_input: bool):\n",
    "        # nie aktualizuj wiedzy bo i tak robione są losowe ruchy\n",
    "        pass\n",
    "\n",
    "    def reset(self):\n",
    "        # nie ma co resetować bo agent jest losowy i nie utrzymuje żadnej wiedzy\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Odpalenie agenta\n",
    "Poniższy kod prezentuje jak przetestować agenta na danej mapie 10 razy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from misio.lost_wumpus import LostWumpusGame\n",
    "from misio.lost_wumpus.testing import default_steps_constraint\n",
    "\n",
    "\n",
    "def test_world(world, agent_class, n=10):\n",
    "    # mapa i odpowiednie prawdopodobieństwa podane w opisie zadania\n",
    "    m, p, pj, pn = world\n",
    "    agent = agent_class(m, p, pj, pn)\n",
    "    # ustawia maksymalną liczbę kroków w zależności od wielkości mapy\n",
    "    max_moves = default_steps_constraint(m)\n",
    "    # tworzy grę\n",
    "    game = LostWumpusGame(m, p, pj, pn, max_moves=max_moves)\n",
    "\n",
    "    run_scores = []\n",
    "    for _ in tqdm.trange(n, leave=False):\n",
    "        # reset agenta (jego wiedzy)\n",
    "        agent.reset()\n",
    "        # reset gry\n",
    "        game.reset()\n",
    "        # póki gra się nie skończy agent działą\n",
    "        while not game.finished:\n",
    "            # wyczuwanie czy jama zostałą wykryta\n",
    "            agent.sense(game.sensory_output)\n",
    "            # wybieranie ruchu\n",
    "            move = agent.move()\n",
    "            # powiadomienie środowiska o ruchu\n",
    "            game.apply_move(move)\n",
    "        # wynik, który chcemy minimalizować\n",
    "        number_of_moves_performed = game.moves\n",
    "        run_scores.append(number_of_moves_performed)\n",
    "    return run_scores\n",
    "\n",
    "# ładuje pierwszą mapa z brzegu\n",
    "world = load_input_file(\"2015.in\")[0]\n",
    "run_scores = test_world(world, RandomAgent,n=200)\n",
    "print(\"Average number of moves: {:0.2f}\".format(np.mean(run_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testowanie\n",
    "Do oceny rozwiązań zostaną użyte dwa pliki 2015.in i 2016.in. By przetestować agenta na każdym świecie można użyć funkcji **test_locally** z pakietu misio.\n",
    "\n",
    "### Punktacja (10 punktów)\n",
    "Każdy świat zostanie przetestowany conajmniej 100 razy, a wyniki uśrednione.\n",
    "Następnie liczba punktów zostanie policzona wedle następującego wzoru:\n",
    "\n",
    "max(0,min(10,(7000-(**score2015** +**score2016**)/2)/(7000-4600)*10))\n",
    "\n",
    "gdzie **score2015** i **score2016** to uśrednione wyniki z odpowiednich plików.\n",
    "\n",
    "Jak widać, uzyskanie  **4600** kroków daje maksymalny wynik 10 punktów, każda wartość poniżej **7000** kroków da zero punktów, a wszelkie wartości pomiędzy są interpolowane liniowo (od 0 do 10).\n",
    "\n",
    "> Uwaga: W przypadku jakiegokolwiek wyjątku rzuconego w wyniku błędnego działania agenta, na którymkolwiek teście ostateczne punkty wyniosą 0 niezależnie od wyników na innych światach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Wczytywanie światów\n",
    "worlds_2015 = load_input_file(\"2015.in\")\n",
    "worlds_2016 = load_input_file(\"2016.in\")\n",
    "# Testowanie:\n",
    "from misio.lost_wumpus.testing import test_locally\n",
    "# przetestuje agenta 5 razy na każdym świecie\n",
    "# 5 testów może dawać niestabilne wyniki, lecz jest szybsze na potrzeby demonstracji\n",
    "# dodatkowo, należy pamiętać, że lepszy wynik będzie testowany krócej\n",
    "# losowy agent jest wyjątkowo zły i jego testowanie zamie sporo czasu\n",
    "score2015 = test_locally(\"2015.in\", RandomAgent, n=5)\n",
    "score2016 = test_locally(\"2016.in\", RandomAgent, n=5)\n",
    "\n",
    "print(\"Average numbers of moves: {:0.1f} & {:0.1f}\".format(score2015, score2016))\n",
    "print(\"Points: {:0.1f}\".format(points))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rozwiązanie (tutaj powinno znajdować się Twoje rozwiązanie)\n",
    "Rozwiązanie musi dziedziczyć po klasie **misio.lost_wumpus.agents.AgentStub** i implementować następujące metody (może też implementować dodatkowe metody):\n",
    "* sense(bool) - aktualizacja wiedzy na podstawie wykrycia (lub nie) jamy\n",
    "* move() - metoda zwracająca jeden z ruchów z klasy misio.lost_wumpus._wumpus.Action\n",
    "* reset() - zresetowanie wiedzy agenta na potrzeby wielu testów na tej samej mapie\n",
    "> Uwaga: Nie twórz dodatkowych komórek na potrzeby rozwiązania i **nie** dopisuj do poniższej komórki żadnego kodu poza **importami** i dowolnymi **nowymi metodami** klasy. Sprawdzarka wczyta tylko tę klasę i ewentualne importy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from misio.lost_wumpus.agents import AgentStub\n",
    "from misio.lost_wumpus._wumpus import Action\n",
    "class LostWumpusAgent(AgentStub):\n",
    "    def __init__(self, m: np.ndarray, p: float, pj: float, pn: float):\n",
    "        super(LostWumpusAgent, self).__init__(m, p, pj, pn)\n",
    "        # TODO dowolna inicjalizacja tutaj\n",
    "    def sense(self, sensory_input: bool):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def move(self):\n",
    "        # TODO wybranie ruchu, zwróć jedną z dozwolonych akcji\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def reset(self):\n",
    "        # TODO zresetowanie wiedzy na potrzeby kolejnego testu na tej samej mapie\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from misio.lost_wumpus.testing import test_locally\n",
    "score2015 = test_locally(\"2015.in\", LostWumpusAgent, n=5)\n",
    "score2016 = test_locally(\"2016.in\", LostWumpusAgent, n=5)\n",
    "\n",
    "points = max(0, min(10, (7000 - (score2015 +score2016)/2)/(7000 - 4600) * 10))\n",
    "print(\"Average numbers of moves: {:0.1f} & {:0.1f}\".format(score2015, score2016))\n",
    "print(\"Points: {:0.1f}\".format(points))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
